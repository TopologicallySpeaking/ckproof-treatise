In the last section, we discussed what <ref ClassicalLogic /> is. In this
section, we will begin to describe how it works. This is a common pattern you
will see throughout this treatise. I'm not sure if there's any kind of deeper
meaning we can derive from it, but this pattern works really well with the proof
checker. First I tell the checker what the symbols are, then I tell it what
rules the symbols follow. After that, it can check any proof I throw at it.

For a human who already has some intuition on logic, the truth tables in the
last chapter are sufficient. However, this does not help a computer to
understand it, nor does it scale to more complicated systems. The correct way to
do this is to define axioms, which are the rules for how a system works. In
particular, it describes the rules for what statements may be derived given a
list of assumptions. As stated on the last page, this is the thing which math
specialized in.

<ref ClassicalLogic /> requires only four axioms. The first three are all of the
same general form:

\Axiom PropSimple: ClassicalLogic {
  name = "The Axiom of Simplification"
  tagline = {
    Before any statement which has already been derived, we may introduce any
    antecedent.
  }
  description = {
    As a simple example, let's say that we have somehow managed to derive that
    ``math is <unicorn>beautiful</unicorn>". Then we may immediately conclude
    that ``if cats rule the world, then math is <unicorn>beautiful</unicorn>".
    Of course, the antecedent introduced can be any statement, even a
    nonsensical one.
  }

  var phi: Prop
  var psi: Prop

  assertion = 'phi => ('psi => 'phi);
}

\Axiom PropDistrib: ClassicalLogic {
  name = "The Axiom of Distribution"
  tagline = {
    The <ref ClassicalLogic.implies /> operator distributes over itself.
  }
  description = {
    Because of the length of this axiom, it's hard to tell what it even means.
    It's easier if you break it down into its antecedent and consequent. The
    antecedent is
    
    \[
      'phi => ('psi => 'chi)
    \],

    and the consequent is

    \[
      ('phi => 'psi) => ('phi => 'chi)
    \].

    Thus, the intuitive way to understand this axiom is, as stated in the
    tagline, that the <ref ClassicalLogic.implies /> operator distributes over
    itself.
  }

  var phi: Prop
  var psi: Prop
  var chi: Prop

  assertion = ('phi => ('psi => 'chi)) => (('phi => 'psi) => ('phi => 'chi));
}

\Axiom PropContra: ClassicalLogic {
  name = "The Axiom of Contraposition"
  tagline = {
    The contrapositive of a statment implies the statement itself.
  }
  description = {
    The contrapositive, if that was unclear, is obtained from the statement
    \('phi => 'psi\) by negating both the antecedent and consequent, then
    swapping their order. In this case, the contrapositive would be
    \(!'psi => !'phi\).
  }

  var phi: Prop
  var psi: Prop

  assertion = (!'psi => !'phi) => ('phi => 'psi);
}

Now's a good time to describe how to use these axioms. These are technically
axiom <em>schemas</em>, each of which stand for infinitely many axioms. Those
variables, which may be recognized by the apostrophe before them, are actually
a placeholder for any expression of the proper type.  For example,
\(p => (p => p)\) is an axiom (provided \(p\) is a proposition) because it can
be derived from <ref ClassicalLogic.PropSimple /> by making the following
substitutions:

<sublist>
  'phi >>> p;
  'psi >>> p;
</sublist>

None of these three axioms have a premise. That is, anywhere in our proof, we
may derive any of these axiom for any reason. If you want an optional exercise,
you can work out the truth table for the axioms and verify that regardless of
which propositions you substitute for the variables, the axioms are always a
true statement.

Obviously, most statements which may derived are not of any of these forms, so
we need more axioms if we want to cover everything. Fortuitously, we only need
one more:

\Axiom ModusPonens: ClassicalLogic {
  name = "Modus Ponens"
  tagline = {
    The derivation rule for <ref ClassicalLogic.implies />.
  }
  description = {
    In the description of <ref ClassicalLogic.implies />, it's mentioned that
    ``as soon as you derive the antecedent \('phi\), you can immediately derive
    the consequent \('psi\)". This is the axiom which allows us to do that.
  }

  var phi: Prop
  var psi: Prop

  premise = [
    'phi => 'psi;
    'phi;
  ]
  assertion = 'psi;
}

This axiom is different from the other three because this axiom has a premise.
Before we may derive the assertion, we must first derive every item in the
premise. That is, when we write a proof and we wish to derive \('psi\) using
<ref ClassicalLogic.ModusPonens />, we must first derive both \('phi => 'psi\)
and \('phi\). Only then may we derive \('psi\).

To prove any theorem, we simply have to find axioms from which we can use
<ref ClassicalLogic.ModusPonens /> to derive the theorem. As an example to see
this in action, let's derive the simplest theorem I can think of: that any
proposition implies itself.

\Theorem PropIdentity: ClassicalLogic {
  name = "Propositional Identity"
  tagline = {
    Propositions imply themselves.
  }

  var phi: Prop

  assertion = 'phi => 'phi;
}

If this were listed as an axiom and not a theorem, then we could just use it in
exactly the same way as any other axiom. However, this is not favorable, as too
many assumptions can become unwieldy. It's very easy to come up with a set of
axioms from which you can derive both a statement and its negation. That is,
some assumptions would claim that this statement is true, while the others claim
it's false. Thus, it's favorable to keep the number of axioms to a minimum.

By marking this as a theorem we are declaring that this theorem is not an
axiom, but rather a fact which may be derived from the axioms. This derivation
is called a ``proof", and once we write the proof we may use the theorem in
exactly the same way as we do the axioms.

\Proof PropIdentity: ClassicalLogic {
  We begin by deriving an axiom in the form of
  <ref ClassicalLogic.PropSimple />.

  |PropSimple, #1| 'phi => ('phi => 'phi => 'phi);.

  Specifically, this axiom is found by making the following substitutions:

  <sublist>
    'phi >>> 'phi;
    'psi >>> ('phi => 'phi);
  </sublist>

  Sometimes, a statement will be too long to easily recognize the substitutions.
  In general for these situations, there will be some text around it to explain
  where it came from. However, if there is still any confusion, there is a link
  at the beginning of every proof to a page which contains detailed information
  on every step of the proof. (NOTE: This feature has not been implemented yet)

  The next step of this proof comes from <ref ClassicalLogic.PropDistrib />
  by making the following substitutions:

  <sublist>
    'phi >>> 'phi;
    'psi >>> ('phi => 'phi);
    'chi >>> 'phi;
  </sublist>

  |PropDistrib, #2| ('phi => ('phi => 'phi => 'phi))
    => (('phi => ('phi => 'phi)) => ('phi => 'phi));.

  As you can probably tell by now, if all proofs were like this, they would be
  too tedious to use for any practical purpose. Fear not, in the next chapter we
  will start to build up quality-of-life improvements so that future proofs
  won't make the reader want to blow their brains out.

  Anyway, take a close look at steps <ref #1 /> and <ref #2 />. The keen-eyed
  among you will have noticed that the antecedent of <ref #2 /> is equal to
  <ref #1 />. This means we can use <ref ClassicalLogic.ModusPonens /> to derive

  |ModusPonens, #3| ('phi => ('phi => 'phi)) => ('phi => 'phi);.

  This is progress because if we can derive \('phi => ('phi => 'phi)\), i.e. the
  antecedent of <ref #3 />, then we can use another round of
  <ref ClassicalLogic.ModusPonens /> to derive the consequent of <ref #3 />,
  which happens to be the thing we want to show.

  Felicitiously, this antecedent happens to be an axiom:

  |PropSimple| 'phi => ('phi => 'phi);.

  Finally, we can derive

  |ModusPonens| 'phi => 'phi;,

  which is what we wanted to show.
}

All that work, and for something so trivial, and believe me it will get worse
before it gets better. Obviously, we will need a better way to do these proofs,
or else the proof checker will be practically unusable. In the next few
sections, we will prove a few more theorems to bootstrap a technique which will
make our lives much easier.
